{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1lSB55Qu24yowactiBSON_ZhRHqejNII5","authorship_tag":"ABX9TyOP12jtgXBh3Q01HqLtxR4F"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Connect to git**"],"metadata":{"id":"8h-bVfjs-d7D"}},{"cell_type":"code","source":["!git --version\n","\n","#configure email and username\n","!git config --global user.email \"riccardo.9giuliani.6@gmail.com\"\n","!git config --global user.name \"Riccardo-Cpt\"\n","\n","#generate temporary token from github https://github.com/settings/tokens\n","\n","token = \"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\"\n","\n","#Create a repository on github named stockData, then clone it on this environment\n","!git clone https://github.com/Riccardo-Cpt/stockData.git\n","\n","#Now the repository is cloned on this environment. Set is as defauld folder. Create main branch\n","%cd stockData\n","#Create main branch and set as default\n","!git checkout -b main\n","#create a file README.md and commit in main branch\n","!echo \"# stockData\" > README.md\n","!git add README.md\n","!git commit -m \"Initial commit on main\"\n","\n","#push all changes (main branch + README) on git\n","path = f\"https://Riccardo-Cpt:{token}@github.com/Riccardo-Cpt/stockData.git\"\n","!git remote set-url origin $path\n","!git push -u origin main"],"metadata":{"id":"Fab9yXGe-XCn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736546546971,"user_tz":-60,"elapsed":2538,"user":{"displayName":"Riccardo Giuliani","userId":"16291267411436588731"}},"outputId":"b9ad101d-2e8d-427b-ff05-ad4b697d7c4a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["git version 2.34.1\n","Cloning into 'stockData'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (3/3), done.\n","/content/stockData\n","fatal: A branch named 'main' already exists.\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Branch 'main' set up to track remote branch 'main' from 'origin'.\n","Everything up-to-date\n"]}]},{"cell_type":"markdown","source":["**Now it is possible to load this notebook inside the git main branch**\n","To do so go to files --> save a copy in Github -->"],"metadata":{"id":"FO30vanESyxY"}},{"cell_type":"code","source":["%ls \"../drive/MyDrive/Colab Notebooks/\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B9GWGEUcOpBn","executionInfo":{"status":"ok","timestamp":1736547209218,"user_tz":-60,"elapsed":377,"user":{"displayName":"Riccardo Giuliani","userId":"16291267411436588731"}},"outputId":"ebc47ac3-6eae-42ac-be03-02ccc7f6468f"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":[" apache-spark-programming-with-databricks-2.3.0.zip   StockData.ipynb   Untitled1.ipynb\n","'Copy of StockData.ipynb'                             Untitled\n"," Pyspark.ipynb                                        Untitled0.ipynb\n"]}]},{"cell_type":"code","source":["# Copio il notebook nel folder drive clonato da git\n","path = \"../drive/MyDrive/Colab\\ Notebooks/StockData.ipynb\"\n","!cp $path \"./\"\n","# Add and commit the file to git\n","!git add \"./StockData.ipynb\"\n","!git commit -m \"Added StockData notebook\"\n","!git push origin main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4r646MrUNx4V","executionInfo":{"status":"ok","timestamp":1736547008094,"user_tz":-60,"elapsed":1097,"user":{"displayName":"Riccardo Giuliani","userId":"16291267411436588731"}},"outputId":"be185710-3ac0-444f-ac65-5e6e55ee554a"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat 'drive/MyDrive/Colab Notebooks/StockData.ipynb': No such file or directory\n","fatal: pathspec './StockData.ipynb' did not match any files\n","On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","nothing to commit, working tree clean\n","Everything up-to-date\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"hQ2JJlmBFnS-"},"outputs":[],"source":["!pip install yfinance\n","import yfinance as yf\n","import pandas as pd\n","import seaborn as sb\n","import datetime\n","import matplotlib.pyplot as plt"]},{"cell_type":"markdown","source":["**S&P500**"],"metadata":{"id":"revLtsOTGQ4-"}},{"cell_type":"markdown","source":["Import from yahoo data sp500 hystory"],"metadata":{"id":"0DA9vxMXdRL3"}},{"cell_type":"code","source":["sp500 = yf.Ticker(\"^GSPC\").history(period=\"max\")\n","sp500 = sp500.drop(columns=['Dividends', 'Stock Splits'])\n","\n","#Extract data from 2006 (note that Date is an index in the dtaframe, not a field)\n","sp500 = sp500[sp500.index > \"2005-12-30 00:00:00-05:00\"]\n","\n","sp500.head()"],"metadata":{"collapsed":true,"id":"umDX_xqvFsL2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Euronext 100**"],"metadata":{"id":"5QBTNE0f8s81"}},{"cell_type":"markdown","source":["Import from yahoo data Euronext 100 hystory"],"metadata":{"id":"2AdCwOCHgF4C"}},{"cell_type":"code","source":["eur100 = yf.Ticker(\"^N100\").history(period=\"max\")\n","eur100 = eur100.drop(columns=['Dividends', 'Stock Splits'])\n","\n","#Extract data from 2006 (note that Date is an index in the dtaframe, not a field)\n","eur100 = eur100[eur100.index > \"2005-12-30 00:00:00-05:00\"]\n","\n","eur100.head()"],"metadata":{"id":"7wuKAzxCd8M-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Amazon**"],"metadata":{"id":"Se4Q5uuU80Tr"}},{"cell_type":"markdown","source":["Import data related to Amazon Company"],"metadata":{"id":"Ohjy4yBpirew"}},{"cell_type":"code","source":["amzn = yf.Ticker(\"AMZN\").history(period=\"max\")\n","amzn = amzn.drop(columns=['Dividends', 'Stock Splits'])\n","\n","#Extract data from 2006 (note that Date is an index in the dtaframe, not a field)\n","amzn = amzn[amzn.index > \"2005-12-30 00:00:00-05:00\"]\n","\n","amzn.head()"],"metadata":{"id":"AMy5T_ORjUaR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Normalizzare Ã¨ necessario per plottare correttamente i dati di amz rispetto gli indici**"],"metadata":{"id":"__vcFRq2J6yj"}},{"cell_type":"code","source":["# def normalize_column(df, column_name):\n","#     \"\"\"\n","#     Normalize a specified column in a DataFrame using Z-score normalization.\n","\n","#     Args:\n","#         df (pd.DataFrame): The DataFrame containing the column to normalize.\n","#         column_name (str): The name of the column to normalize.\n","\n","#     Returns:\n","#         pd.Series: A new column with normalized values.\n","#     \"\"\"\n","#     mean = df[column_name].mean()\n","#     std = df[column_name].std()\n","#     return (df[column_name] - mean) / std\n","\n","# # Apply normalization to each dataset\n","# sp500[\"Close_norm\"] = normalize_column(sp500, \"Close\")\n","# eur100[\"Close_norm\"] = normalize_column(eur100, \"Close\")\n","# amzn[\"Close_norm\"] = normalize_column(amzn, \"Close\")\n","\n","\n","\n","import numpy as np\n","\n","def log_transform_column(df, column_name):\n","    \"\"\"\n","    Apply a log transformation to a column in a DataFrame.\n","\n","    Args:\n","        df (pd.DataFrame): The DataFrame containing the column to transform.\n","        column_name (str): The name of the column to transform.\n","\n","    Returns:\n","        pd.Series: A new column with log-transformed values.\n","    \"\"\"\n","    return np.log(df[column_name])\n","\n","# Apply log transformation to each dataset\n","sp500[\"Close_log\"] = log_transform_column(sp500, \"Close\")\n","eur100[\"Close_log\"] = log_transform_column(eur100, \"Close\")\n","amzn[\"Close_log\"] = log_transform_column(amzn, \"Close\")\n"],"metadata":{"id":"-hgG5ehMHvzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_col = \"Close_log\"\n","\n","# Plotting the amazon data\n","sb.lineplot(data=amzn, x=amzn.index, y=y_col, label=\"AMZN\", color=\"red\")\n","\n","# Plotting the S&P 500 data\n","sb.lineplot(data=sp500, x=sp500.index, y=y_col, label=\"S&P 500\", color=\"green\")\n","\n","# # Plotting the EUR 100 data\n","sb.lineplot(data=eur100, x=eur100.index, y=\"Close\", label=\"EUR 100\", color=\"blue\")\n","\n","\n","# Adding plot title and labels\n","plt.title(\"S&P 500 vs EUR 100 vs AMZN Close Prices\")\n","plt.xlabel(\"Date\")\n","plt.ylabel(\"Close Price\")\n","\n","# Show legend\n","plt.legend()\n","\n","# Display the plot\n","plt.show()"],"metadata":{"id":"9KJEB_vWG7tj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Quanto avrei guadaganto oggi se avessi investito 1000 euro l'1 marzo  su S&P 500.\n","sp500_start = sp500[sp500.index == \"2012-03-01 00:00:00-05:00\"]\n","\n","start_investment = sp500_start[\"Open\"][0]\n","start_investment\n"],"metadata":{"id":"si-NNtiyJbr5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from datetime import datetime\n","from datetime import timedelta\n","\n","# datetime object containing current date and time\n","now = datetime.now() -timedelta(days = 1)\n","dt_string = now.strftime(\"%Y-%m-%d 00:00:00-05:00\")\n","sp500_now = sp500[sp500.index == dt_string]\n","end_investment = sp500_now[\"Open\"][0]\n","\n"],"metadata":{"id":"fXl69Wx8TgDC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["end_investment/start_investment*1000"],"metadata":{"id":"UUIHlOhjTfzd"},"execution_count":null,"outputs":[]}]}